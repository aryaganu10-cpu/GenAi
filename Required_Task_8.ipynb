{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXkJEiPujHOg3WXopHwknZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryaganu10-cpu/GenAi/blob/main/Required_Task_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "0H9HQP7ypTGM",
        "outputId": "76bf2ad1-3927-47bd-9a5f-24597fef8c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.7.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAE***************************vqks. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1628223820.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1193\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         )\n\u001b[0;32m-> 1297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAE***************************vqks. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# Risk Divergence Analysis Script\n",
        "# ================================\n",
        "\n",
        "!pip install pypdf\n",
        "import os\n",
        "import re\n",
        "from pypdf import PdfReader\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# --------------------------\n",
        "# 1. Setup OpenAI Client\n",
        "# --------------------------\n",
        "\n",
        "client = OpenAI(api_key=userdata.get(\"SECRET_NAME\"))\n",
        "\n",
        "# --------------------------\n",
        "# 2. PDF Extraction Function\n",
        "# --------------------------\n",
        "\n",
        "def extract_text_from_pdf(path):\n",
        "    reader = PdfReader(path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# --------------------------\n",
        "# 3. Extract Risk Factors Section\n",
        "# --------------------------\n",
        "\n",
        "def extract_risk_section(text):\n",
        "    risk_start = re.search(r\"Item\\s+1A\\.\\s+Risk\\s+Factors\", text, re.IGNORECASE)\n",
        "    risk_end = re.search(r\"Item\\s+1B\\.\", text, re.IGNORECASE)\n",
        "\n",
        "    if risk_start and risk_end:\n",
        "        return text[risk_start.start():risk_end.start()]\n",
        "    else:\n",
        "        return text  # fallback if regex fails\n",
        "\n",
        "# --------------------------\n",
        "# 4. Load 10-K Files\n",
        "# --------------------------\n",
        "\n",
        "block_text = extract_text_from_pdf(\"Block 10K 2023.pdf\")\n",
        "paypal_text = extract_text_from_pdf(\"PayPal 10K 2023.pdf\")\n",
        "\n",
        "block_risk = extract_risk_section(block_text)\n",
        "paypal_risk = extract_risk_section(paypal_text)\n",
        "\n",
        "# Truncate to manageable length\n",
        "block_risk = block_risk[:20000]\n",
        "paypal_risk = paypal_risk[:20000]\n",
        "\n",
        "# --------------------------\n",
        "# 5. Prompt Variations\n",
        "# --------------------------\n",
        "\n",
        "prompts = {\n",
        "    \"baseline\": \"\"\"\n",
        "Compare the Risk Factors sections of Block and PayPal.\n",
        "Identify operational, legal, and strategic risk differences.\n",
        "Focus on Bitcoin, AI, and ecosystem expansion vs. efficiency strategy.\n",
        "\"\"\",\n",
        "    \"forensic\": \"\"\"\n",
        "Act as a forensic financial analyst.\n",
        "Detect subtle wording shifts, newly introduced risk disclosures,\n",
        "and/or potential undisclosed operational vulnerabilities.\n",
        "Focus on AI, Bitcoin, TBD, and ecosystem expansion.\n",
        "\"\"\",\n",
        "    \"contrarian\": \"\"\"\n",
        "Assume Block's AI & Bitcoin expansion hides operational fragility.\n",
        "Argue whether their risk disclosures understate legal, regulatory,\n",
        "or liquidity exposure compared to PayPal.\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# --------------------------\n",
        "# 6. Run Analysis Prompts\n",
        "# --------------------------\n",
        "\n",
        "analysis_results = {}\n",
        "\n",
        "for key, prompt in prompts.items():\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-5\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a senior SEC risk analyst.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt +\n",
        "             \"\\n\\nBLOCK RISK FACTORS:\\n\" + block_risk +\n",
        "             \"\\n\\nPAYPAL RISK FACTORS:\\n\" + paypal_risk}\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    analysis_results[key] = response.choices[0].message.content\n",
        "\n",
        "# --------------------------\n",
        "# 7. LLM as Judge\n",
        "# --------------------------\n",
        "\n",
        "judge_prompt = \"\"\"\n",
        "You are an expert financial risk professor.\n",
        "Evaluate which analysis best identifies undisclosed\n",
        "operational or legal risks in Block compared to PayPal.\n",
        "Rate each from 1-10 and explain why.\n",
        "\"\"\"\n",
        "\n",
        "judge_response = client.chat.completions.create(\n",
        "    model=\"gpt-5\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an impartial evaluator.\"},\n",
        "        {\"role\": \"user\", \"content\": judge_prompt +\n",
        "         \"\\n\\nBASELINE:\\n\" + analysis_results[\"baseline\"] +\n",
        "         \"\\n\\nFORENSIC:\\n\" + analysis_results[\"forensic\"] +\n",
        "         \"\\n\\nCONTRARIAN:\\n\" + analysis_results[\"contrarian\"]}\n",
        "    ],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "judge_output = judge_response.choices[0].message.content\n",
        "\n",
        "print(\"===== JUDGE EVALUATION =====\")\n",
        "print(judge_output)\n",
        "\n",
        "# --------------------------\n",
        "# 8. Generate Final Executive Summary\n",
        "# --------------------------\n",
        "\n",
        "synopsis_prompt = \"\"\"\n",
        "Write a 200-word Executive Summary answering:\n",
        "Is Block's AI & Bitcoin focus creating undisclosed\n",
        "operational risks compared to PayPal's conservative strategy?\n",
        "Use the judge's evaluation and strongest findings.\n",
        "\"\"\"\n",
        "\n",
        "synopsis_response = client.chat.completions.create(\n",
        "    model=\"gpt-5\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a strategic consultant writing to a board of directors.\"},\n",
        "        {\"role\": \"user\", \"content\": synopsis_prompt +\n",
        "         \"\\n\\nJUDGE OUTPUT:\\n\" + judge_output}\n",
        "    ],\n",
        "    temperature=0.4\n",
        ")\n",
        "\n",
        "executive_summary = synopsis_response.choices[0].message.content\n",
        "\n",
        "print(\"\\n===== EXECUTIVE SUMMARY =====\")\n",
        "print(executive_summary)\n",
        "\n",
        "# --------------------------\n",
        "# 9. Optional: Save Results\n",
        "# --------------------------\n",
        "\n",
        "with open(\"risk_divergence_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"JUDGE EVALUATION:\\n\")\n",
        "    f.write(judge_output)\n",
        "    f.write(\"\\n\\nEXECUTIVE SUMMARY:\\n\")\n",
        "    f.write(executive_summary)\n",
        "\n",
        "print(\"\\nResults saved to risk_divergence_results.txt\")"
      ]
    }
  ]
}